The Plan

There are areas of development that must be worked on: 
 1. The Hearing Aid Device PHL and Mac programming and algorithm development
 2. Determination of affecting audio elements affecting intelligibility.
 3. The Cloud Machine Learning support.
 4. Course work to add skills and get an understanding of intelligibility
These areas will be worked in parallel.

1. Hearing Aid Device
  - Switch from the openMHA build it yourself RaspberryPi based heading aid to the openMHA 
    hearing aid research platform produced by Bat and Cat Sound Labs 
    * The device was obtained June 28, 2021, approved by NIH and provided free of charge

  - Install openMHA version 4.16.0 on Mac 
    * accomplished July 1, 2021

  - Install openMHA version 4.17.0 on Mac and on PHL. This allows doing the audio processing
     on both PHL and Mac. Implement the hearing aid logic such that it can be used on either 
     device for ease in development.
    * accom[plished Dec 2022

  - Become fluent in the MatLab version of mhacontrol, so that the device can be used

  - Become fluent with Pythonista in order to run a Python based GUI on iPhone to control PHL

  - Configure PHL to mimic the ReSound hearing aids recently obtained by DSP.
    * Have obtained the audiogram from Mayo
    * Have obtained the NAL-NL2 prescription used by Mayo to fit the ReSound hearing aids.

  - Collect sample environments.
    * Collect using iPhone voice capture app
    * Create Python code for PHL to record environments on demand using the PHL mics
    * Add a playback mechanism to use when exploring settings
    * Utilize these to start to categorize and adjust settings 

 2. Determine how settings are changed in response to particular environments.
    * Consider a couple of approaches 
       1) look in recognizing complete environments like talking with a specific people 
          and adjusting audio characteristics based on the recognized voice.
          * Coordinate with the Cloud ML activity to be able to associate settings with 
            environments
          * Devise a mechanism to score the setting with the environment.
          * Devise a mechanism to improve setting when it does not meet user's needs for a given
            environment
          * Devise a mechanism to capture and send to Cloud newly recognized environments.       
       2) use phonemes as the basis of creating clarity. (I often note that sound level and pitch
           might be adequate but still can't make out some words.) This approach would first 
           identify 
          troublesome phonemes, and then a corrective action would be determined. That action
          would then be applied in real time.
          * Identify troublesome phonemes perhaps through running examples and getting
            feedback
            or possibly use real-time feedback in actual conversations.
          * Once troublesome phonemes are identified, determine what signal processing/audio 
            processing action improves the intelligibility.

        3) Determine how settings are changed to make the enhanced sounds and voices not only 
            clear, but pleasant to the hearer.
          * Devise mechanism to quantify "pleasant"
          * Understand available settings that influence "pleasantness"
          * Devise mechanism to associate quality of pleasant with different environments
 
3. Cloud Machine Learning support
   - Obtain Google Research Cloud access for TPU accelerated processing
    * Have access repeatedly
    
  - Start the process of categorizing environments
    * Receive environment samples with identifying id
    * develop training mechanisms to identify environments
  - Start the process of troublesome phoneme identification
    * Possibly through repeated random phoneme generation and user response
    * Possibly through real-time conversation monitoring.
  
4. Educate myself in sound, and audio processing
   - Taking classes at U of M as a grad student (even though retired)
     * Machine Learning Intro , Advanced
     * Advanced Bioelectronics
     * Artificial Intelligence I and II
     * Time Series Analysis
     * Digital Signal Processing
     * Natural Language Processing
     * Speech Science
     * The Sense of Hearing
     * Neural Engineering
     * Phonetics

